## [tf.nn.softmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits)的用法
```python
import tensorflow as tf

#our NN's output
logits=tf.constant([[1.0,2.0,3.0],[1.0,2.0,3.0],[1.0,2.0,3.0]])
#step1:do softmax
y=tf.nn.softmax(logits)
#true label
y_=tf.constant([[0.0,0.0,1.0],[0.0,0.0,1.0],[0.0,0.0,1.0]])
#step2:do cross_entropy
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
#do cross_entropy just one step
cross_entropy2=tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits, y_))#dont forget tf.reduce_sum()!!

with tf.Session() as sess:
    softmax=sess.run(y)
    c_e = sess.run(cross_entropy)
    c_e2 = sess.run(cross_entropy2)
    print("step1:softmax result=")
    print(softmax)
    print("step2:cross_entropy result=")
    print(c_e)
    print("Function(softmax_cross_entropy_with_logits) result=")
    print(c_e2)
```
输出结果  
```python
step1:softmax result=
[[ 0.09003057  0.24472848  0.66524094]
 [ 0.09003057  0.24472848  0.66524094]
 [ 0.09003057  0.24472848  0.66524094]]
step2:cross_entropy result=
1.22282
Function(softmax_cross_entropy_with_logits) result=
1.2228
```

## 激活函数  

1. Rectified Linear Unit(ReLU) - 用于隐层神经元输出  
2. Sigmoid - 用于隐层神经元输出  
3. Softmax - 用于多分类神经网络输出  
4. Linear - 用于回归神经网络输出（或二分类问题）  
* Softmax激活函数只用于多于一个输出的神经元，它保证所以的输出神经元之和为1.0，所以一般输出的是小于1的概率值，可以很直观地比较各输出值。

## sys.stdout.flush()  
* 在Linux系统下，必须加入sys.stdout.flush()才能刷新输出(程序运行到此处是显示之前的输出)   
* 在Windows系统下，加不加sys.stdout.flush()都能刷新输出

## 关于FLAGS
```python
tf.app.flags.DEFINE_boolean("self_test", False, "True if running a self test.")  
FLAGS.self_test = True
print ('out of main',FLAGS.self_test)  
def main(argv=None): 
    print ("in main",FLAGS.self_test)
```
结果是：  

> <type 'bool'>  
> out of main True  
> in main False
  
  猜测in main false 的原因是在程序执行前已经将false编译进main
  
## [训练集(train set) 验证集(validation set) 测试集(test set)](http://www.cnblogs.com/xfzhang/archive/2013/05/24/3096412.html)
这三个名词在机器学习领域的文章中极其常见，但很多人对他们的概念并不是特别清楚，尤其是后两个经常被人混用。Ripley, B.D（1996）在他的经典专著Pattern Recognition and Neural Networks中给出了这三个词的定义。  
* Training set: A set of examples used for learning, which is to fit the parameters [i.e., weights] of the classifier.   
* Validation set: A set of examples used to tune the parameters [i.e., architecture, not weights] of a classifier, for example to choose the number of hidden units in a neural network.   
* Test set: A set of examples used only to assess the performance [generalization] of a fully specified classifier.  

显然，training set是用来训练模型或确定模型参数的，如ANN中权值等； validation set是用来做模型选择（model selection），即做模型的最终优化及确定的，如ANN的结构；而 test set则纯粹是为了测试已经训练好的模型的推广能力。当然，test set这并不能保证模型的正确性，他只是说相似的数据用此模型会得出相似的结果。但实际应用中，一般只将数据集分成两类，即training set 和test set，大多数文章并不涉及validation set。
Ripley还谈到了  
  
  Why separate test and validation sets?
1. The error rate estimate of the final model on validation data will be biased (smaller than the true error rate) since the validation set is used to select the final model.
2. After assessing the final model with the test set, YOU MUST NOT tune the model any further.

## Failed to create session  
错误信息上溯Total memory：11GiB  Free memory：475MiB 错误原因是内存不足。解决方法是重启pycharm。  

## python enumerate()使用  
* 如果对一个列表，既要遍历索引又要遍历元素时，首先可以这样写：  
```python
list1 = ["这", "是", "一个", "测试"]
for i in range (len(list1)):
    print i ,list1[i]
```
* 上述方法有些累赘，利用enumerate()会更加直接和优美：
```python
list1 = ["这", "是", "一个", "测试"]
for index, item in enumerate(list1):
    print index, item
>>>
0 这
1 是
2 一个
3 测试
```

* enumerate还可以接收第二个参数，用于指定索引起始值，如：
```python
list1 = ["这", "是", "一个", "测试"]
for index, item in enumerate(list1, 1):
    print index, item
>>>
1 这
2 是
3 一个
4 测试
```

## glob.glob  
返回所有匹配的文件路径列表。它只有一个参数pathname，定义了文件路径匹配规则，这里可以是绝对路径，也可以是相对路径。下面是使用glob.glob的例子：
```python
import glob  
  
#获取指定目录下的所有图片  
print glob.glob(r"E:\Picture\*\*.jpg")  
  
#获取上级目录的所有.py文件  
print glob.glob(r'../*.py') #相对路径  

# 另：
cate = [path + x for x in os.listdir(path) if os.path.isdir(path + x)]
imgs = []
labels = []
for idx, folder in enumerate(cate):
    for im in glob.glob(folder + '/*.' + image_format):
        print('reading the images:%s' % (im))
        img = io.imread(im)
        img = transform.resize(img, (setting.resize_w, setting.resize_h))
        imgs.append(img)
        labels.append(idx)
```

## numpy中array和asarray的区别
array和asarray都可以将结构数据转化为ndarray，但是主要区别就是当数据源是ndarray时，array仍然会copy出一个副本，占用新的内存，但asarray不会。
举例说明：
```python
import numpy as np

#example 1:
data1=[[1,1,1],[1,1,1],[1,1,1]]
arr2=np.array(data1)
arr3=np.asarray(data1)
data1[1][1]=2
print 'data1:\n',data1
print 'arr2:\n',arr2
print 'arr3:\n',arr3
```
输出：
```python
data1:
[[1, 1, 1], [1, 2, 1], [1, 1, 1]]
arr2:
[[1 1 1]
 [1 1 1]
 [1 1 1]]
arr3:
[[1 1 1]
 [1 1 1]
 [1 1 1]]
```
可见array和asarray没有区别，都对元数据进行了复制。  
```python
import numpy as np

#example 2:
arr1=np.ones((3,3))
arr2=np.array(arr1)
arr3=np.asarray(arr1)
arr1[1]=2
print 'arr1:\n',arr1
print 'arr2:\n',arr2
print 'arr3:\n',arr3
```
输出：  
```python
arr1:
[[ 1.  1.  1.]
 [ 2.  2.  2.]
 [ 1.  1.  1.]]
arr2:
[[ 1.  1.  1.]
 [ 1.  1.  1.]
 [ 1.  1.  1.]]
arr3:
[[ 1.  1.  1.]
 [ 2.  2.  2.]
 [ 1.  1.  1.]]
```
此时可以看出两者的区别。  
其中[[1,1,1],[1,1,1],[1,1,1]] 和np.ones((3,3))
前者是list(list)后者是ndarray

## InteractiveSession  
InteractiveSession是默认的session，这就意味着你可以在不声明session的条件下直接使用run()，eval() 。这在interactive shells 和 IPython notebooks 中非常方便！  
```python
sess = tf.InteractiveSession()
a = tf.constant(5.0)
b = tf.constant(6.0)
c = a * b
# We can just use 'c.eval()' without passing 'sess'
print(c.eval())
sess.close()
```

## assert
如何为assert断言语句添加异常参数,assert的异常参数，其实就是在断言表达式后添加字符串信息，用来解释断言并更好的知道是哪里出了问题。一般来说是程序员开发库等东西的时候给再次开发的程序员看的。格式如下：
>assert expression [, arguments]  
>assert 表达式 [, 参数]  


自定异常
```python
class ShortInputException(Exception):
    '''自定义的异常类'''
    def __init__(self, length, atleast):
        #super().__init__()
        self.length = length
        self.atleast = atleast

def main():
    try:
        s = input('请输入 --> ')
        if len(s) < 3:
            # raise引发一个你定义的异常
            raise ShortInputException(len(s), 3)
    except ShortInputException as result:#x这个变量被绑定到了错误的实例
        print('ShortInputException: 输入的长度是 %d,长度至少应是 %d'% (result.length, result.atleast))
    else:
        print('没有异常发生.')

main()
```
## 统一资源定位符（URL）Uniform Resource Locator
基本URL包含模式:（或称协议）、服务器名称（或IP地址）、路径和文件名，如“协议://授权/路径?查询”。完整的、带有授权部分的普通统一资源标志符语法看上去如下：协议://用户名:密码@子域名.域名.顶级域名:端口号/目录/文件名.文件后缀?参数=值#标志
