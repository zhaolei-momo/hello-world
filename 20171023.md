## [tf.nn.softmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits)的用法
```python
import tensorflow as tf

#our NN's output
logits=tf.constant([[1.0,2.0,3.0],[1.0,2.0,3.0],[1.0,2.0,3.0]])
#step1:do softmax
y=tf.nn.softmax(logits)
#true label
y_=tf.constant([[0.0,0.0,1.0],[0.0,0.0,1.0],[0.0,0.0,1.0]])
#step2:do cross_entropy
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
#do cross_entropy just one step
cross_entropy2=tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits, y_))#dont forget tf.reduce_sum()!!

with tf.Session() as sess:
    softmax=sess.run(y)
    c_e = sess.run(cross_entropy)
    c_e2 = sess.run(cross_entropy2)
    print("step1:softmax result=")
    print(softmax)
    print("step2:cross_entropy result=")
    print(c_e)
    print("Function(softmax_cross_entropy_with_logits) result=")
    print(c_e2)
```
输出结果  
```python
step1:softmax result=
[[ 0.09003057  0.24472848  0.66524094]
 [ 0.09003057  0.24472848  0.66524094]
 [ 0.09003057  0.24472848  0.66524094]]
step2:cross_entropy result=
1.22282
Function(softmax_cross_entropy_with_logits) result=
1.2228
```

## 激活函数  

1. Rectified Linear Unit(ReLU) - 用于隐层神经元输出  
2. Sigmoid - 用于隐层神经元输出  
3. Softmax - 用于多分类神经网络输出  
4. Linear - 用于回归神经网络输出（或二分类问题）  
* Softmax激活函数只用于多于一个输出的神经元，它保证所以的输出神经元之和为1.0，所以一般输出的是小于1的概率值，可以很直观地比较各输出值。

## sys.stdout.flush()  
* 在Linux系统下，必须加入sys.stdout.flush()才能刷新输出(程序运行到此处是显示之前的输出)   
* 在Windows系统下，加不加sys.stdout.flush()都能刷新输出

## 关于FLAGS
```python
tf.app.flags.DEFINE_boolean("self_test", False, "True if running a self test.")  
FLAGS.self_test = True
print ('out of main',FLAGS.self_test)  
def main(argv=None): 
    print ("in main",FLAGS.self_test)
```
结果是：  

> <type 'bool'>  
> out of main True  
> in main False
  
  猜测in main false 的原因是在程序执行前已经将false编译进main
  
## 训练集(train set) 验证集(validation set) 测试集(test set)
这三个名词在机器学习领域的文章中极其常见，但很多人对他们的概念并不是特别清楚，尤其是后两个经常被人混用。Ripley, B.D（1996）在他的经典专著Pattern Recognition and Neural Networks中给出了这三个词的定义。  
* Training set: A set of examples used for learning, which is to fit the parameters [i.e., weights] of the classifier.   
* Validation set: A set of examples used to tune the parameters [i.e., architecture, not weights] of a classifier, for example to choose the number of hidden units in a neural network.   
* Test set: A set of examples used only to assess the performance [generalization] of a fully specified classifier.  
显然，training set是用来训练模型或确定模型参数的，如ANN中权值等； validation set是用来做模型选择（model selection），即做模型的最终优化及确定的，如ANN的结构；而 test set则纯粹是为了测试已经训练好的模型的推广能力。当然，test set这并不能保证模型的正确性，他只是说相似的数据用此模型会得出相似的结果。但实际应用中，一般只将数据集分成两类，即training set 和test set，大多数文章并不涉及validation set。
Ripley还谈到了  
Why separate test and validation sets?  
1. The error rate estimate of the final model on validation data will be biased (smaller than the true error rate) since the validation set is used to select the final model.
2. After assessing the final model with the test set, YOU MUST NOT tune the model any further.
